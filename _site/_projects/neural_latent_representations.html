<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>DeepSleepBench - Shaswat Gupta</title>
<meta name="description" content="Benchmarking Neural Latent Representations on EEG data for Sleep Stage Classification">


  <meta name="author" content="Shaswat Gupta">
  


<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Shaswat Gupta">
<meta property="og:title" content="DeepSleepBench">
<meta property="og:url" content="http://localhost:4000/_projects/neural_latent_representations.html">


  <meta property="og:description" content="Benchmarking Neural Latent Representations on EEG data for Sleep Stage Classification">



  <meta property="og:image" content="http://localhost:4000/assets/images/projects/latent.jpg">










<link rel="canonical" href="http://localhost:4000/_projects/neural_latent_representations.html">












<!-- end _includes/seo.html -->


<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
  
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css"></noscript>


 <link
  href="https://fonts.googleapis.com/css2?family=Merriweather:wght@300;400;700;900&family=Inter:wght@300;400;500;600;700&display=swap"
  rel="stylesheet"
/>

    <style>
      body {
        font-size: 0.9em;
      }
    </style>
  </head>

  <body
    class="layout--default"
  >
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>
 

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/assets/images/logo.png" alt="Shaswat Gupta"></a>
        
        <a class="site-title" href="/">
          Shaswat Gupta
          <span class="site-subtitle">ETH Zurich | IIT Bombay Rank 1, Gold Medalist | ML Engineer</span>
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a
                href="/cv/"
                
                
              >About Me</a>
            </li><li class="masthead__menu-item">
              <a
                href="/analyses/"
                
                
              >Executive Theses</a>
            </li><li class="masthead__menu-item">
              <a
                href="/projects/"
                
                
              >Projects</a>
            </li><li class="masthead__menu-item">
              <a
                href="/courses/"
                
                
              >Intellectual Vault</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content"><p><img src="/assets/images/projects/bench-framework-diagram.svg" alt="DeepSleepBench Framework" /></p>

<h1 id="benchmarking-neural-latent-representations-for-eeg-based-sleep-stage-classification">Benchmarking Neural Latent Representations for EEG-based Sleep Stage Classification</h1>

<p><a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT" /></a>
<a href="https://www.python.org/downloads/"><img src="https://img.shields.io/badge/python-3.8+-blue.svg" alt="Python 3.8+" /></a>
<a href="https://pytorch.org/"><img src="https://img.shields.io/badge/PyTorch-2.0.0+-red.svg" alt="PyTorch 2.0+" /></a>
<a href="https://www.tensorflow.org/tensorboard"><img src="https://img.shields.io/badge/TensorBoard-Enabled-green.svg" alt="TensorBoard" /></a></p>

<h2 id="overview">Overview</h2>

<p>Sleep stage classification (SSC) is fundamental for diagnosing sleep disorders and understanding sleep physiology. However, the effectiveness of self-supervised learning (SSL) paradigms for electroencephalogram (EEG) data remains incompletely explored. DeepSleepBench provides a systematic benchmark of three SSL paradigms paired with different neural architectures for EEG-based SSC.</p>

<div class="page__download" style="text-align:center; margin: 2em 0;">
  <a href="https://github.com/RaphaelKreft/DeepLearningProject" class="btn btn--primary" target="_blank" rel="noopener">
    <i class="fab fa-github"></i> View on GitHub
  </a>
</div>

<div class="page__download" style="text-align:center; margin: 2em 0;">
  <a href="/assets/files/benchmarking_neural_representations.pdf" class="btn btn--primary" download="">
    <i class="fas fa-file-pdf"></i> Download Full Report (PDF)
  </a>
</div>

<p><strong>Our contribution:</strong></p>
<ul>
  <li>Comprehensive evaluation of SSL paradigms (Contrastive, Masked Prediction, Hybrid)</li>
  <li>Ablation studies across neural architectures (CNN, CNN+Attention, Transformer)</li>
  <li>Novel metrics for latent space quality assessment</li>
  <li>State-of-the-art performance on public sleep datasets</li>
</ul>

<h2 id="key-results">Key Results</h2>

<table>
  <thead>
    <tr>
      <th>Model/Paradigm</th>
      <th>Architecture</th>
      <th>Accuracy (%)</th>
      <th>Macro-F1</th>
      <th>Cohen’s κ</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>CRL</td>
      <td>CNN</td>
      <td>76.9</td>
      <td>66.1</td>
      <td>0.670</td>
    </tr>
    <tr>
      <td>CRL</td>
      <td>CNN+Attn</td>
      <td><strong>79.8</strong></td>
      <td><strong>69.2</strong></td>
      <td><strong>0.715</strong></td>
    </tr>
    <tr>
      <td>CRL</td>
      <td>Transformer</td>
      <td>49.5</td>
      <td>29.4</td>
      <td>0.265</td>
    </tr>
    <tr>
      <td>MP</td>
      <td>CNN</td>
      <td>63.9</td>
      <td>50.8</td>
      <td>0.486</td>
    </tr>
    <tr>
      <td>MP</td>
      <td>CNN+Attn</td>
      <td>69.0</td>
      <td>53.9</td>
      <td>0.552</td>
    </tr>
    <tr>
      <td>MP</td>
      <td>Transformer</td>
      <td>62.5</td>
      <td>48.4</td>
      <td>0.462</td>
    </tr>
    <tr>
      <td>Hybrid</td>
      <td>CNN</td>
      <td>78.8</td>
      <td>68.7</td>
      <td>0.700</td>
    </tr>
    <tr>
      <td>Hybrid</td>
      <td>CNN+Attn</td>
      <td>78.9</td>
      <td>67.7</td>
      <td>0.702</td>
    </tr>
    <tr>
      <td>Hybrid</td>
      <td>Transformer</td>
      <td>56.4</td>
      <td>41.6</td>
      <td>0.374</td>
    </tr>
  </tbody>
</table>

<p>Our findings reveal that <strong>CNN+Attention with Contrastive Learning</strong> achieves superior performance, while hybrid approaches provide a balanced alternative for EEG-based sleep staging.</p>

<h2 id="installation">Installation</h2>

<h3 id="prerequisites">Prerequisites</h3>
<ul>
  <li>CUDA-compatible GPU (tested on NVIDIA RTX 3090)</li>
  <li>Python 3.8+</li>
  <li>PyTorch 2.0+</li>
</ul>

<h3 id="option-1-using-conda-recommended">Option 1: Using Conda (Recommended)</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Clone the repository</span>
git clone https://github.com/YourUsername/DeepSleepBench.git
<span class="nb">cd </span>DeepSleepBench

<span class="c"># Create and activate conda environment</span>
conda <span class="nb">env </span>create <span class="nt">-f</span> sleepnet_environment.yaml
conda activate sleepnet
</code></pre></div></div>

<h3 id="option-2-using-pip">Option 2: Using pip</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Clone the repository</span>
git clone https://github.com/YourUsername/DeepSleepBench.git
<span class="nb">cd </span>DeepSleepBench

<span class="c"># Create a virtual environment</span>
python <span class="nt">-m</span> venv venv
<span class="nb">source </span>venv/bin/activate  <span class="c"># On Windows: venv\Scripts\activate</span>

<span class="c"># Install PyTorch (adjust according to your CUDA version)</span>
pip <span class="nb">install </span><span class="nv">torch</span><span class="o">==</span>2.0.0 <span class="nv">torchvision</span><span class="o">==</span>0.15.0 <span class="nv">torchaudio</span><span class="o">==</span>2.0.0 <span class="nt">--index-url</span> https://download.pytorch.org/whl/cu118

<span class="c"># Install other dependencies</span>
pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
</code></pre></div></div>

<h2 id="dataset-preparation">Dataset Preparation</h2>

<h3 id="sleep-edf-dataset">Sleep-EDF Dataset</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Download the Sleep-EDF-2018 dataset</span>
<span class="nb">cd</span> ./dset/Sleep-EDF-2018
python download_sleep-edf-2018.py

<span class="c"># Preprocess EDF files into NPZ format</span>
python prepare_sleep-edf-2018.py
</code></pre></div></div>

<h2 id="framework-architecture">Framework Architecture</h2>

<p>DeepSleepBench evaluates three distinct backbone architectures:</p>

<h3 id="1-cnn-backbone">1. CNN Backbone</h3>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Conv-Block ×5 → Feature Pyramid (c3,c4,c5)
               ↘                     ↘
            AvgPool1d(1)         Decoder (mirror arch)
               ↘                     ↘
            128-D latent      Reconstruction (for MP)
</code></pre></div></div>

<h3 id="2-cnnattention-backbone">2. CNN+Attention Backbone</h3>
<p>Extends the CNN architecture with transformer-style attention mechanisms for capturing long-range temporal dependencies:</p>
<ul>
  <li>Self-attention blocks after the last two encoder/decoder stages</li>
  <li>Multi-head attention with add &amp; norm operations</li>
  <li>Same latent head dimensionality (128-D) for fair comparison</li>
</ul>

<h3 id="3-transformer-backbone">3. Transformer Backbone</h3>
<p>Two-stage pipeline for handling EEG signals:</p>
<ol>
  <li>Optional <code class="language-plaintext highlighter-rouge">SignalBackbone</code>: Tri-branch ResNet-style feature extractor for 5s signal windows</li>
  <li><code class="language-plaintext highlighter-rouge">AutoEncoderViT</code>: Vision Transformer with masked auto-encoder capability
    <ul>
      <li>Linear patch projection</li>
      <li>Sinusoidal positional embeddings</li>
      <li>CLS token for classification</li>
    </ul>
  </li>
</ol>

<h2 id="self-supervised-learning-paradigms">Self-Supervised Learning Paradigms</h2>

<p>DeepSleepBench evaluates three SSL paradigms:</p>

<h3 id="1-contrastive-representation-learning-crl">1. Contrastive Representation Learning (CRL)</h3>
<p>Trains the encoder to discriminate between different instances while pulling together augmented views of the same epoch.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Run CRL pre-training with CNN+Attention backbone</span>
python train_crl_dlproj.py <span class="nt">--config</span> configs/DLPROJ_pretrain_CRL_CNN_Attention_Sleep-EDF-2018.json <span class="nt">--gpu</span> 0
</code></pre></div></div>

<h3 id="2-masked-prediction-mp">2. Masked Prediction (MP)</h3>
<p>Reconstructs masked portions of the input signal, forcing the model to learn temporal dependencies.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Run MP pre-training with Transformer backbone</span>
python train_mp.py <span class="nt">--config</span> configs/DLPROJ_pretrain_MP_Transformer_Sleep-EDF-2018.json <span class="nt">--gpu</span> 0
</code></pre></div></div>

<h3 id="3-hybrid-approach-crl--mp">3. Hybrid Approach (CRL + MP)</h3>
<p>Combines both objectives to leverage complementary learning signals.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Run Hybrid pre-training with CNN backbone</span>
python train_hybrid.py <span class="nt">--config</span> configs/DLPROJ_pretrain_Hybrid_CNN_Sleep-EDF-2018.json <span class="nt">--gpu</span> 0
</code></pre></div></div>

<h2 id="latent-space-evaluation">Latent Space Evaluation</h2>

<p>Our framework includes comprehensive tools for evaluating latent space quality:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Evaluate embeddings from a pre-trained model</span>
python latent_space_evaluator.py <span class="nt">--config</span> configs/DLPROJ_pretrain_CRL_CNN_Sleep-EDF-2018.json
</code></pre></div></div>

<h3 id="supported-metrics">Supported Metrics</h3>

<h4 id="cluster-quality-metrics">Cluster Quality Metrics</h4>
<ul>
  <li><strong>Silhouette Score</strong> ↑: Measures how similar points are to their own cluster vs. other clusters</li>
  <li><strong>Davies-Bouldin Index</strong> ↓: Ratio of within-cluster distances to between-cluster distances</li>
  <li><strong>Purity</strong> ↑: Proportion of cluster members belonging to the dominant class</li>
  <li><strong>Average Entropy</strong> ↓: Information theory measure of cluster label homogeneity</li>
</ul>

<h4 id="label-aware-metrics">Label-Aware Metrics</h4>
<ul>
  <li><strong>Adjusted Rand Index</strong> ↑: Corrected-for-chance measure of cluster-label agreement</li>
  <li><strong>Adjusted Mutual Information</strong> ↑: Normalized measure of shared information</li>
</ul>

<h4 id="topology--geometry-metrics">Topology &amp; Geometry Metrics</h4>
<ul>
  <li><strong>Trustworthiness</strong> ↑: Preservation of local neighborhoods after dimensionality reduction</li>
  <li><strong>Alignment</strong> ↑: Correlation between original and reduced distance matrices</li>
  <li><strong>Compactness-to-Separation Ratio</strong> ↓: Balance between intra-class and inter-class distances</li>
</ul>

<h3 id="visualization-methods">Visualization Methods</h3>
<ul>
  <li><strong>t-SNE</strong>: Non-linear dimensionality reduction preserving local structure</li>
  <li><strong>UMAP</strong>: Manifold learning algorithm balancing local and global structure</li>
  <li><strong>PCA</strong>: Linear baseline for sanity checks</li>
</ul>

<p>Sample visualization of latent spaces for different model architectures:</p>

<p><img src="/assets/images/projects/latent_space.png" alt="Latent Space" /></p>

<h2 id="advanced-usage">Advanced Usage</h2>

<h3 id="configuration-system">Configuration System</h3>

<p>DeepSleepBench uses a flexible JSON/YAML configuration system for experiment customization:</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"exp_name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"CRL_CNN_Sleep-EDF-2018"</span><span class="p">,</span><span class="w">
  </span><span class="nl">"backbone"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"CNN"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"params"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"in_channels"</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
      </span><span class="nl">"initial_filters"</span><span class="p">:</span><span class="w"> </span><span class="mi">16</span><span class="p">,</span><span class="w">
      </span><span class="nl">"kernel_size"</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w">
      </span><span class="nl">"dropout"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.5</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"trainer"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"batch_size"</span><span class="p">:</span><span class="w"> </span><span class="mi">128</span><span class="p">,</span><span class="w">
    </span><span class="nl">"learning_rate"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.001</span><span class="p">,</span><span class="w">
    </span><span class="nl">"weight_decay"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.0001</span><span class="p">,</span><span class="w">
    </span><span class="nl">"max_epochs"</span><span class="p">:</span><span class="w"> </span><span class="mi">500</span><span class="p">,</span><span class="w">
    </span><span class="nl">"early_stopping_patience"</span><span class="p">:</span><span class="w"> </span><span class="mi">10</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"data"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"dataset"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Sleep-EDF-2018"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"sampling_rate"</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span><span class="w">
    </span><span class="nl">"epoch_duration"</span><span class="p">:</span><span class="w"> </span><span class="mi">30</span><span class="w">
  </span><span class="p">},</span><span class="w">
  </span><span class="nl">"ssl"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
    </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"CRL"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"params"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
      </span><span class="nl">"temperature"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.1</span><span class="p">,</span><span class="w">
      </span><span class="nl">"augmentations"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="s2">"RandomBandStopFilter"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"RandomTimeShift"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"RandomZeroMasking"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"TimeWarping"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"Permutation"</span><span class="p">,</span><span class="w">
        </span><span class="s2">"CutoutResize"</span><span class="w">
      </span><span class="p">]</span><span class="w">
    </span><span class="p">}</span><span class="w">
  </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<h3 id="data-augmentation-suite">Data Augmentation Suite</h3>

<p>Our framework includes six specialized signal augmentations:</p>

<ol>
  <li><strong>RandomBandStopFilter</strong>: Removes random frequency bands</li>
  <li><strong>RandomTimeShift</strong>: Applies temporal shifts with random offsets</li>
  <li><strong>RandomZeroMasking</strong>: Masks random segments with zeros</li>
  <li><strong>TimeWarping</strong>: Non-uniformly stretches/compresses segments</li>
  <li><strong>Permutation</strong>: Divides and reorders signal segments</li>
  <li><strong>CutoutResize</strong>: Removes segments and resizes remaining parts</li>
</ol>

<p>Each augmentation is applied with probability 0.5 to ensure sufficient distortion while preserving essential information.</p>

<h3 id="custom-training-recipes">Custom Training Recipes</h3>

<h4 id="hybrid-training-balance-tuning">Hybrid Training Balance Tuning</h4>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nl">"alpha_crl"</span><span class="p">:</span><span class="w"> </span><span class="mi">10</span><span class="w">  </span><span class="err">//</span><span class="w"> </span><span class="err">Adjust</span><span class="w"> </span><span class="err">weight</span><span class="w"> </span><span class="err">between</span><span class="w"> </span><span class="err">CRL</span><span class="w"> </span><span class="err">and</span><span class="w"> </span><span class="err">MP</span><span class="w"> </span><span class="err">objectives</span><span class="w">
</span></code></pre></div></div>

<h4 id="masking-difficulty-control">Masking Difficulty Control</h4>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nl">"masking_ratio"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.50</span><span class="w">  </span><span class="err">//</span><span class="w"> </span><span class="err">Hide</span><span class="w"> </span><span class="mi">50</span><span class="err">%</span><span class="w"> </span><span class="err">of</span><span class="w"> </span><span class="err">signal</span><span class="w"> </span><span class="err">(higher</span><span class="w"> </span><span class="err">=</span><span class="w"> </span><span class="err">harder)</span><span class="w">
</span></code></pre></div></div>

<h4 id="faster-experimentation">Faster Experimentation</h4>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nl">"val_period"</span><span class="p">:</span><span class="w"> </span><span class="mi">128</span><span class="err">,</span><span class="w">  </span><span class="err">//</span><span class="w"> </span><span class="err">Validate</span><span class="w"> </span><span class="err">every</span><span class="w"> </span><span class="mi">128</span><span class="w"> </span><span class="err">mini-batches</span><span class="w">
</span><span class="nl">"early_stopping"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nl">"patience"</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="p">}</span><span class="err">,</span><span class="w">
</span><span class="nl">"max_epochs"</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span><span class="w">
</span></code></pre></div></div>

<h2 id="code-structure">Code Structure</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DeepSleepBench/
├── configs/                  # Training configuration files
├── dset/                     # Dataset download and preprocessing
├── models/                   # Model architectures
│   ├── cnn/                  # CNN backbone implementation
│   ├── cnn_attention/        # CNN+Attention backbone 
│   ├── transformer/          # Transformer backbone
│   └── main_model_dlproj.py  # Model factory and integration
├── latent_space_evaluation/  # Latent space metrics and viz tools
│   ├── reducers.py           # t-SNE, UMAP, PCA dimensionality reduction
│   ├── metrics.py            # 13 cluster quality metrics
│   ├── plotter.py            # Visualization utilities
│   └── test_script.py        # CLI for evaluation
├── train_crl_dlproj.py       # Contrastive learning training
├── train_mp.py               # Masked prediction training
├── train_hybrid.py           # Hybrid approach training
├── loss.py                   # Loss function implementations
├── utils.py                  # Utility functions
├── requirements.txt          # pip dependencies
└── sleepnet_environment.yaml # Conda environment specification
</code></pre></div></div>

<h2 id="training-pipeline">Training Pipeline</h2>

<p>Our training pipeline follows a standardized workflow:</p>

<ol>
  <li><strong>Self-supervised pre-training</strong>:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python train_crl_dlproj.py <span class="nt">--config</span> configs/DLPROJ_pretrain_CRL_CNN_Attention_Sleep-EDF-2018.json <span class="nt">--gpu</span> 0
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Automatic embedding generation</strong>:
The framework automatically generates embeddings for evaluation after pre-training.</p>
  </li>
  <li><strong>Linear evaluation</strong>:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Automatically performed after pre-training</span>
<span class="c"># Or run separately:</span>
python classifier_training.py <span class="nt">--encoder_ckpt</span> ckpts/cnn_pretrain.pt <span class="nt">--config</span> configs/classifier_cnn.json
</code></pre></div>    </div>
  </li>
  <li><strong>Benchmarking</strong>:
    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># For comprehensive latent space evaluation</span>
python latent_space_evaluator.py <span class="nt">--config</span> configs/DLPROJ_pretrain_CRL_CNN_Sleep-EDF-2018.json
</code></pre></div>    </div>
  </li>
</ol>

<h2 id="monitoring--artifacts">Monitoring &amp; Artifacts</h2>

<ul>
  <li><strong>TensorBoard logs</strong>: Available at <code class="language-plaintext highlighter-rouge">logs/&lt;config-name&gt;/fold-1/</code></li>
  <li><strong>Checkpoints</strong>: Saved to <code class="language-plaintext highlighter-rouge">checkpoints/&lt;config-name&gt;/ckpt_fold-01.pth</code></li>
  <li><strong>Embeddings</strong>: Dumped to <code class="language-plaintext highlighter-rouge">checkpoints/&lt;config-name&gt;/embeddings.pt</code></li>
  <li><strong>Visualizations</strong>: Generated in <code class="language-plaintext highlighter-rouge">results/&lt;config-name&gt;/</code></li>
</ul>

<p>To view TensorBoard logs:</p>
<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tensorboard <span class="nt">--logdir</span> logs/
</code></pre></div></div>

<h2 id="troubleshooting">Troubleshooting</h2>

<h3 id="common-issues">Common Issues</h3>

<h4 id="out-of-memory-errors">Out-of-Memory Errors</h4>
<ul>
  <li>Reduce batch size in configuration</li>
  <li>Use PyTorch 2.0+ for improved memory efficiency</li>
  <li>For Transformer models, consider reducing attention heads</li>
</ul>

<h4 id="training-instability">Training Instability</h4>
<ul>
  <li>For CRL, ensure batch size ≥ 128 for stable contrastive gradients</li>
  <li>Adjust temperature parameter (start with 0.1, increase if unstable)</li>
  <li>Start with lower learning rates for Transformer models</li>
</ul>

<h4 id="missing-masking-errors">Missing Masking Errors</h4>
<p>For Hybrid/MP training, ensure:</p>
<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nl">"masking"</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span></code></pre></div></div>
<p>is set in the dataset configuration block.</p>

<h2 id="future-work">Future Work</h2>

<ul>
  <li>Extension to multi-channel EEG classification</li>
  <li>Cross-dataset domain adaptation</li>
  <li>Integration with additional sleep datasets (MASS, SHHS)</li>
  <li>Advanced transformer architectures with EEG-specific adaptations</li>
  <li>Real-time inference optimizations for clinical deployment</li>
</ul>

<h2 id="acknowledgments">Acknowledgments</h2>

<p>This project builds upon several excellent works in the field of sleep stage classification:</p>

<ul>
  <li>SleePyCo (<a href="https://doi.org/10.1016/j.eswa.2023.122551">Lee et al., 2024</a>)</li>
  <li>MAEEG (<a href="https://arxiv.org/abs/2211.02625">Chien et al., 2022</a>)</li>
  <li>NeuroNet (<a href="https://arxiv.org/abs/2404.17585">Lee et al., 2024</a>)</li>
</ul>

<p>We thank the authors of these papers for making their research accessible.</p>

<h2 id="license">License</h2>

<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>
</div>

    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets --> <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
          <li><a href="https://github.com/Shaswat-G" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
          <li><a href="https://www.linkedin.com/in/shaswat-gupta/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
        
      
        
          <li><a href="https://shazzgo.substack.com/" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-newspaper" aria-hidden="true"></i> Substack</a></li>
        
      
        
          <li><a href="mailto:shagupta@ethz.ch" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
        
      
    

    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 <a href="http://localhost:4000">Shaswat Gupta</a>. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/jekyll-themes/minimal-mistakes/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.4/jquery.min.js"></script>
    <script src="/assets/js/plugins/jquery.greedy-navigation.js"></script>
    <!-- <script src="/assets/js/main.min.js"></script> -->

     
  </body>
</html>
